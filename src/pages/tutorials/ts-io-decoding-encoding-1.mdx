export const meta = {
  title: 'Tutorial: I/O Data Decoding/Encoding Library from Scratch in TypeScript',
  category: 'tutorials',
  type: 'tutorial',
  slug: 'ts-io-decoding-encoding-1',
  tagline:
    'Build your own library from scratch that decodes and encodes data. Deep-dive into TypeScript!',
  tags: ['TypeScript'],
  ogImageUrl: 'banner.png',
  publishedOn: '2024-11-27',
  seriesName: 'TypeScript Decoding/Encoding Library',
  seriesSlug: 'ts-io-decoding-encoding',
  seriesIndex: 1,
  seriesLastIndex: 3,
  readingTime: 40,
}

import Image from 'next/image'
import {
  BlockQuote,
  EmphasisBox,
  Figure,
  KnowledgeCheck,
  MarginNote,
  NewConcept,
  SideNote,
  Spoiler,
} from '../../components/blog'
import { ArticlePage } from '../../layouts/ArticlePage'

<EmphasisBox>

**Intended Audience**:

- People who enjoy hands-on learning by building things
- Anyone who has used a TypeScript library for input parsing/validation (`io-ts`, `effect-ts`, `zod`, `joi`, `yup`, etc.) and would like to learn how these work

**Recommended Proficiency Level**:

- Beginner to intermediate programmer
- Familiar with common TypeScript code, including type parameters ("generics")
- No additional advanced feature knowledge required -- every advanced topic will be introduced and explained individually

**Learning Method**:

This is a hands-on tutorial, just reading through won't get you much. You'll get the most out of it by actually firing up a code editor and following along! You can also follow along on the [TypeScript playground](https://www.typescriptlang.org/play/) for most of the tutorial (excluding tests).

The final/full source code is available at: [https://github.com/davimiku/ts-io-decoding-encoding#part-1](https://github.com/davimiku/ts-io-decoding-encoding/tree/part-1)

</EmphasisBox>

## Introduction

In this tutorial, we will learn how to create a library in TypeScript that does decoding and encoding of data.

This is split into three articles:

1. Decoding (this article)
2. [Custom decoders and better errors](./ts-io-decoding-encoding-2)
3. [Encoding](./ts-io-decoding-encoding-3)

First off, what do these terms mean? Or more specifically, how will I, the author, use these terms?

**Decoding** is the act of converting incoming data from a less structured format into a more structured format by checking if the data matches an expected shape or not. This can also include _transforming_ the data into that expected shape if it is compatible, depending on the rules that the programmer defines. This is also referred to as "parsing", "deserializing", or "marshalling" - but the term "decoding" will be used throughout the rest of the article (see the Appendix for justification).

{/* prettier-ignore */}
<MarginNote id='decoding-fail'> Decoding failures are expected and non-exceptional any time we're dealing with input outside of our control</MarginNote>The input data (`Input`) either matches or can be transformed to match the desired shape (`T`), otherwise there is an error (`Error`).

<Figure
  src='/images/blog/tutorials/ts-io-decoding-encoding-1/decode.svg'
  caption='flow diagram of decoding input data into either the expected data or an error'
/>

**Encoding** is taking data in a known structure (`T`) and converting it back to some kind of output format (`Output`).

<Figure
  src='/images/blog/tutorials/ts-io-decoding-encoding-1/encode.svg'
  caption='previous flow diagram of decoding with a new step added of encoding the data into an output format'
/>

<Spoiler summary="Decoding vs. Validating">

Another common term for dealing with incoming data is "validation", and our definition of "decoding" contains validation as **part** of the process. Decoding consists of:

1. (Optional) transforming the data towards the desired shape
2. Validation - check that the actual shape matches the desired shape
3. Information retention - the type system needs to **remember** the results of our validation. If it immediately forgets what we validated, then that's a difference between validation and decoding

An overly simplified example of something that does #2 (validation) but not #3 (retain that information) is null/nil checks in a lot of languages. Consider the Go code below, where the type system doesn't remember that we checked for `nil` already, and we either have to check it again in different functions every time we use that data, or just trust that it is what we think it is.

```go
func NeedsARectangle(rectangle *Rectangle) {
  if rectangle != nil {
    // do some stuff...
    AlsoNeedsARectangle(nil)
  }
}

func AlsoNeedsARectangle(rectangle *Rectangle) {
  // The type system doesn't retain the knowledge that we already
  // validated so we either validate again or risk a SIGSEGV in
  // the future (maybe?)
  if rectangle != nil {
    fmt.Println("not nil")
  }
}
```

[Parse, Don't Validate](https://lexi-lambda.github.io/blog/2019/11/05/parse-don-t-validate/) is an essay with a more thorough explanation of this terminology difference.

<Spoiler summary="another example">

You better believe we do nested spoilers!

Another short example of **information retention** vs. not, consider this implementation of `isArray`.

```typescript
function isArray(input: unknown): boolean {
  return Array.isArray(input)
}
```

Of course this is a silly function because you would normally just call `Array.isArray` directly. But this example returns a `boolean`, which means the type system immediately forgets the good work we just did.

<Figure
  src='/images/blog/tutorials/ts-io-decoding-encoding-1/validating_without_information_retention.png'
  caption="returning a boolean doesn't help us retain information through the rest of the program"
/>

Throughout the rest of the tutorial, we'll learn how to make this better.

<KnowledgeCheck>

Why is the built-in `Array.isArray` better than our contrived example here? What language feature does it use that is unique to TypeScript?

</KnowledgeCheck>

</Spoiler>

</Spoiler>

## Who cares?

Why is it beneficial to learn how to implement this?

For me, I think it's a couple of reasons:

1.) Basically every program ever written involves decoding data in, doing something with it, and encoding data back out. The middle part of that could be simple or extremely complex, but that's still the gist.

Occasionally, we need to dive deep into seemingly mundane topics to come out with a greater sense of understanding on the other side. Taking some time to focus on the little details every now and then is like... eating your vegetables, or something like that. Even Michael Jordan practiced free throws, I think.

<BlockQuote
  content="If you find that you're spending almost all your time on theory, start turning some attention to practical things; it will improve your theories. If you find that you're spending almost all your time on practice, start turning some attention to theoretical things; it will improve your practice."
  footer='Donald Knuth, "Theory and Practice". Theoretical Computer Science, 1991'
></BlockQuote>

2.) I also think that _library development_ is an underappreciated and underdeveloped skill in many software engineers. There's no shortage of _application development_ tutorials, courses, guides, etc. but comparatively fewer for library development.

This isn't even about making a popular open-source library, in every company's codebase there is a section that would be considered "core library" code (whether it's explicitly recognized as such or not). The quality of this core library has massive impacts on the quality and reliability of what the company produces and the productivity of the engineers who produce it.

## How do we actually do this?

Rant over! From poking around a bit, I could find four ways to achieve decoding/encoding across different languages and ecosystems:

1. The programmer defines the types, and then another process generates code for decoding/encoding during compilation

- **Examples**: [serde](https://crates.io/crates/serde) (Rust), [typia](https://typia.io/docs/setup/) (TypeScript)
- Accomplished using macros, compiler plugins, comptime code, etc.

2. The programmer defines the decoding/encoding, then derives the type

- **Examples**: [effect](https://effect.website/docs/schema/introduction/), [io-ts](https://gcanti.github.io/io-ts/), [zod](https://zod.dev/) (TypeScript)
- This is most popular in (and maybe exclusive to) TypeScript due to the built-in `typeof` operator that can derive types from values

3. Runtime reflection is used to compare incoming data to expected field types
4. The programmer manually defines both the types and decoding/encoding code

Each of these approaches has advantages and disadvantages. There's also a 5th "approach" where you just... don't do any of this, like call `JSON.parse(input)` or whatever and assume it's the desired shape.

<Figure
  src='/images/blog/tutorials/ts-io-decoding-encoding-1/as_any.png'
  caption='TypeScript devs resolving compiler errors'
/>

In this tutorial, we'll learn how to build #2 - a library that allows a programmer to define the decoding/encoding code and derive their types from that.

A sneak peek of the desired functionality of our library is below. If you've used similar libraries in the past, this should be familiar, but otherwise everything will be explained each step of the way!

```typescript
import * as io from 'our-new-library'

// Creates the "Shape" that can be used to decode or encode data
const Rectangle = io.struct({
  width: io.number,
  height: io.number,
})

// The plain type can be inferred from the "Shape"
type Rectangle = io.Infer<typeof Rectangle>
//    ^?       = { width: number, height: number }

// Incoming `unknown` data can be decoded into a `Rectangle` or an error
const result = Rectangle.decode(incomingData)
//                                  ^? unknown

if (result.isSuccess) {
  // If it was decoded successfully, we can use the typed data
  console.log('width:', result.width, 'height:', result.height)
} else {
  // Otherwise, we can see errors of why it was not successful
  console.log(result.error)
}
```

## Getting started

Enough talk, let's go!

Unfortunately, starting a TypeScript project has more options than a menu at The Cheesecake Factory. Feel free to use your own preferred setup, or you can use the [tutorial source code part 1](https://github.com/davimiku/ts-io-decoding-encoding/tree/part-1) as a starting point. I'm using NodeJS v22 (LTS at the time of writing) using TypeScript with ES Modules, and [vitest](https://vitest.dev/) for testing.

Crank open the `src/index.ts` file (or whatever equivalent in your setup of choice)!

### What's the data?

In my [last tutorial](/tutorials/json-parsing-rust-1), I advised that the best thing to do when looking into the bottomless abyss (i.e. a blank module that you just started working on) is to define the data first!

We'll also focus on **decoding** first, because that's harder and it's also the feature that would be used more.

The central type which will be used everywhere and link everything together will be called `Shape`. This could also be called `Schema`, `Type`, or even `Codec` if you like (a [Codec](https://en.wikipedia.org/wiki/Codec) is a thing that both decodes and encodes, so it's probably the right word, but it sounds like, nerdy or whatever).

```typescript
interface Shape<T> {
  readonly __tag: string
  readonly decode: (input: unknown) => T
}
```

<Spoiler summary="`type` vs. `interface`">

Though I prefer defining types with the `type` keyword, the `interface` keyword is used specifically here for a very subtle reason not defined anywhere in the documentation (as far as I know). More on that later, for now, this will have to be a cliffhanger to hold your attention!

**Edit - 2024-12-08**

In a draft version of the library while I was working on this tutorial I had to use `interface` for Shape instead of `type`. It appears evaluating `interface`s (in the type context) is done in 2 steps, declaration and then evaluation ("lazy") whereas `type` is done in a single step ("eager"). This should mean that there's more scenarios that recursive types would work with `interface` rather than `type`.

However, whether it was due to refactoring, different version of TypeScript, or just something I misremembered, it appears that the `type` keyword can be used in this situation after all.

To avoid changing the tutorial, the `interface` keyword will still be used for `Shape`.

</Spoiler>

<NewConcept title="<T>: Type Parameters">

The `<T>` and `T` in the type above are **type parameters**, sometimes referred to as "generics". Like how functions have parameters, and then you can use those parameters in the body of your function, types can also have parameters that you can use in the body of the type.

In this case, this type represents:

- An object with a `__tag` field that is a `string`
- and a `decode` field that is a function
  - which takes input of an `unknown` type and returns data of the same type `T` that was passed in as a parameter

</NewConcept>

## Built-ins: Primitives

We need to define the building blocks, or "built-in types" of our library that our users (other programmers) can build from.

```typescript
interface Shape<T> {
  /* ...snip... */
}

interface ShapeBoolean extends Shape<boolean> {
  readonly __tag: 'boolean'
}

interface ShapeString extends Shape<string> {
  readonly __tag: 'string'
}

interface ShapeNumber extends Shape<number> {
  readonly __tag: 'number'
}
```

<Spoiler summary="...snip... ?">

Throughout the tutorial, I use comments with `...snip...` that indicate that this particular code is building on a previous code snippet.

</Spoiler>

We started with (the types corresponding to) three of the [primitive values](https://developer.mozilla.org/en-US/docs/Glossary/Primitive) - `boolean`, `number`, and `string`. Of the remainder, it doesn't really make sense to include `null` or `undefined` as generic building blocks, and I'm omitting `symbol` from this tutorial for the sake of brevity. The remaining primitive value is `bigint`, which we will get to a bit later because it's slightly more interesting.

<NewConcept title="<T>: Type Arguments">

This is really the other half of the previous summary of Type Parameters. Whenever we say something like `Shape<number>`, the `number` is the **argument** passed in to the `Shape` type. The best way to think of it is a function that runs at compile-time, pass a type in, get a type out. In this example, `number` would be substituted in for `T` inside the body of the type.

</NewConcept>

We actually have one more "built-in" shape to add, corresponding to the `unknown` type.

```typescript
interface Shape<T> {
  /* ...snip... */
}

interface ShapeUnknown extends Shape<unknown> {
  readonly __tag: 'unknown'
}
```

This could be useful for people who are decoding data without a statically defined shape which they'll deal with outside of our library, or for fields that they don't care about, which are essentially "pass-through".

The next step is to provide an implementation of these built-in shapes, and these shapes are what other people will compose together to make what they need.

```typescript
// ...snip...

export const unknown: ShapeUnknown = {
  __tag: 'unknown',
  decode: (input: unknown): unknown => input,
} as const
```

This is going to be the simplest implementation of `decode`, since it returns the same data it's given (the [identity function](https://en.wikipedia.org/wiki/Identity_function)). This satisfies the type because the type parameter `T` from `Shape<T>` is substituted with `unknown`.

<NewConcept title="`as const`">

This annotation can go after a value and it makes it readonly at **compile-time**. This is different from [Object.freeze](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/freeze) which is a built-in JavaScript function that makes an object readonly at runtime (and TypeScript also recognizes this and makes it readonly at compile-time).

Why do this at all? When something shouldn't be mutated, it should be marked as such, just as much for communication as it is for communication. "Self documenting code" includes annotations like this, because how else would you document "this object must not be mutated"?

When you work with languages where immutability is the default and can be opted-out, you end up missing that in languages where mutability is the default.

</NewConcept>

The rest will be a little different! Decoding into `unknown` is **infallible**, by definition of `unknown`. But decoding into `boolean` is not infallible, because the input data might not be a boolean!

```typescript
export const boolean: ShapeBoolean = {
  __tag: 'boolean',
  decode: (input: unknown): boolean => {
    if (typeof input !== 'boolean') {
      throw new Error('oopsy whoopsy!')
    }
    return input
  },
} as const
```

{/* prettier-ignore */}
<MarginNote id='excape-hatch'>Libaries can include "escape hatches" that use more powerful/dangerous/unexpected behavior for certain use cases, but we need to be very careful about what the **default** behavior is</MarginNote>We're doing a cop-out here by throwing a <del>tantrum</del> exception when things don't go our way. Incoming data not conforming to a certain shape is not exceptional, it's expected (as evidenced by us having code that checks for this, we **expect** this is a possibility). I feel rather strongly that libraries should not throw exceptions unless absolutely necessary, and definitely shouldn't throw them by default.

We'll fix this later in the tutorial, for now, we march onwards!

<EmphasisBox>

We could have actually implemented this built-in shape with infallible decoding by making it use truthiness of the incoming data to **transform** it into a boolean (truthy -> `true`, falsy -> `false`). In other words, if someone used our built-in `boolean` shape and the input data was `"hello world"`, should that coerce to `true`?

Would this be **useful** to include in a building block? If it's useful, does it make sense for it to be the **default** behavior?

Questions for a library author such as yourself to ponder!

</EmphasisBox>

Next is `number`, which follows a similar pattern:

```typescript
export const number: ShapeNumber = {
  __tag: 'number',
  decode(input: unknown): number {
    if (typeof input !== 'number') {
      throw new Error('oopsy whoopsy!')
    }
    return input
  },
} as const
```

Pretty easy, right?

<EmphasisBox>

Not so fast! There are more decisions for this library author (you) to make.

1. Should `NaN` be a success or failure?
2. Should `Infinity` and `-Infinity` be success or failure?

<Spoiler summary="my thoughts">

I would say "failure" to both of these questions, as the times I've actually wanted `NaN` or `+-Infinity` data are few and far between. It's useful for this shape to actually represent "finite number" (should we rename it? 🤔). Still, a library author needs to consider all possible use cases if someone actually wants `NaN` or `+-Infinity` and try to come up with a flexible solution that allows everyone to get what they want!

</Spoiler>

</EmphasisBox>

String should be simple (I think?). This implementation is straight-forward, where any string (including empty string) passes:

```typescript
export const string: ShapeString = {
  __tag: 'string',
  decode(input: unknown): string {
    if (typeof input !== 'string') {
      throw new Error('oopsy whoopsy!')
    }
    return input
  },
} as const
```

{/* prettier-ignore */}
<MarginNote id="transform-becomes">Unlike a [type predicate](https://www.typescriptlang.org/docs/handbook/2/narrowing.html#using-type-predicates) which is "Input is T", think of this transform as... "Input becomes T". Conceptually at least - there is no `becomes` keyword</MarginNote>BigInt is more interesting in that it touches on one of the topics from the introduction, we can **transform** the data before decoding, transformation can be part of the overall process.

```typescript
interface ShapeBigInt extends Shape<bigint> {
  readonly __tag: 'bigint'
}

export const bigint: ShapeBigInt = {
  __tag: 'bigint',
  decode(input: unknown): bigint {
    if (typeof input === 'bigint') {
      return input
    } else if (typeof input === 'number' && !Number.isNaN(input) && Number.isFinite(input)) {
      return BigInt(input)
    }
    throw new Error('oopsy whoopsy!')
  },
} as const
```

In this implementation, if the data is already a `bigint` it passes, or if it's a finite `number` it's promoted to a `bigint` and passes, otherwise fails. This seems like a reasonable default behavior, except there's still a question of numbers with a fractional component, like `1.2`. Should those still be coerced into `bigint`, losing the fraction part? Or should that fail?

## Built-ins: Inference

Let's go back to the desired usage/capabilities of our library from the introduction:

```typescript
import * as io from 'our-new-library'

// ...snip...

// The plain type can be inferred from the "Shape"
type Rectangle = io.Infer<typeof Rectangle>
//    ^?       = { width: number, height: number }

// ...snip...
```

We want to provide our users with this `Infer` type, so that they can define their shapes and infer their types from their shapes. Notice that this `Infer` type has a **type parameter**, so we'll henceforth<SideNote id="henceforth">It's using words like "henceforth" that gets me out of bed in the mornings</SideNote> refer to it as `Infer<Shape>`.

<NewConcept title="`typeof` operator (type context)">

The `typeof` keyword in the previous code example is the key to this entire part, and it's **not** this [typeof operator](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/typeof) from JavaScript.

There are two contexts, the value context and the type context. This article discusses this concept with a clear diagram and explanation, that's worth reading at least the introduction: [An introduction to type programming in TypeScript](https://www.zhenghao.io/posts/type-programming).

The `typeof` operator used here is in the **type context** and it is a one-way path from the value context to the type context. Like the `typeof` operator from the value context, it is a **unary** operator, meaning it takes one argument. The argument that it **takes** is a value from the value context.

</NewConcept>

Implementing this `Infer<Shape>` type is actually fairly mechanical, and not too "clever", though it uses a more advanced TypeScript feature which we'll introduce now.

We'll build it up piece by piece, starting with `unknown`:

```typescript
export type Infer<S extends Shape<unknown>> = unknown
```

This infers `unknown` for every possible shape, which... is not very useful<SideNote id="yet">yet</SideNote>.

<Figure
  src='/images/blog/tutorials/ts-io-decoding-encoding-1/cmon_do_something.jpg'
  caption='Developers using a decoder that only infers `unknown`'
/>

<NewConcept title="`extends` as a constraint">

The `extends` keyword, when used in a **type context**, provides a contraint on a type parameter. This is not to be confused with the `extends` keyword in a value context which is for a class to inherit from another class<SideNote id="extends">The TypeScript team historically tries to reuse keywords for the type context where possible, rather than inventing new keywords, which is mostly a good thing</SideNote>.

When I see this keyword, in my head I read it as "is constrained to be" or "is a subtype of". Ruby uses the `<` symbol to indicate a subtype relationship, which I kind of love, but type parameters in TypeScript already use `<>` which would be hard to read.

What this says, is similar to how we can constrain the values passed in to functions, which can also constrain the types passed into other types. Remember, types with parameters are more like functions that run at compile-time. In this case, whatever is passed in as `S` must constrain to being a subtype of `Shape<unknown>`. The actual `Shape<unknown>` itself is valid too, because types are already subtypes of themselves by definition.

</NewConcept>

Let's get a little more useful, and add boolean:

{/* prettier-ignore */}
```typescript
export type Infer<S extends Shape<unknown>> = S extends ShapeUnknown
  ? unknown
  : S extends ShapeBoolean
    ? boolean
    : never
```

See what I mean by "mechanical"? It's not very exciting, we'll add a new case for every possible built-in shape in a big if/else chain.

<NewConcept title="`extends` as a condition">

We see the same `extends` keyword again, in a type context again, but still different<SideNote id="maybe-not-good-after-all">Maybe not a good idea to reuse keywords after all</SideNote>. In this position, it is part of a [conditional type](https://www.typescriptlang.org/docs/handbook/2/conditional-types.html) (expression) where it **checks** if the parameter `S` is a subtype of `ShapeUnknown` and executes the first branch if true and the second branch if false.

As an aside, there's no concept of "truthy"/"falsy" in these conditional types, if you do want a boolean result then it has to be explicit:

```typescript
type IsFalse = 'hello' extends number ? true : false
type IsTrue = 'hello' extends string ? true : false
```

</NewConcept>

<Spoiler summary="What could have been">

We need to use this `c ? x : y` conditional operator because `if`/`else` and `switch` are **statements** rather than expressions in JavaScript. The TypeScript team prefers to design the type context syntax similar to the value context syntax, so this operator was brought into the type context as-is (they _could have_ made `if`/`else` and `switch` an _expression_ in the type context, but it also might have confused people).

This is one of the reasons why some people write off this kind of compiletime code completely, because the syntax is borderline unreadable. I think that's completely valid, I also think it's fine for a library to take this "syntactic salt" upon itself if it means applications become simpler or easier (it's certainly easier to generate decoders like we're doing than to write bespoke decoding logic for every single data type that an application uses). There's a new, interesting [programming language called Zig](https://ziglang.org/documentation/master/#comptime) that asks "what if compiletime syntax actually wasn't bad?" which I think is pretty cool.

So we're stuck with this syntax, and it'll get worse throughout the rest of the tutorial. If only JavaScript had been more like [Scheme](<https://en.wikipedia.org/wiki/Scheme_(programming_language)>) as originally intended! We may have had expression-oriented programming as the base rather than statement-oriented programming with expressions trying to be bolted on later like [match expressions](https://github.com/tc39/proposal-pattern-matching?tab=readme-ov-file#expression-semantics) and [do expressions](https://github.com/tc39/proposal-do-expressions).

</Spoiler>

Let's add the rest of the built-in shapes we have so far.

{/* prettier-ignore */}
```typescript
export type Infer<S extends Shape<unknown>> = S extends ShapeUnknown
  ? unknown
  : S extends ShapeBoolean
    ? boolean
    : S extends ShapeNumber
      ? number
      : S extends ShapeString
        ? string
        : S extends ShapeBigInt
          ? bigint
          : never
```

<NewConcept title="`never` type">

We saw it in the previous code, but I deferred it to here in the pursuit of "one new concept at a time".

`never` is the "bottom type", the subtype of all other types. Types represent sets of possible values, and the `never` type is the empty set, there is no possible value that has a type of `never`. Things like infinite loops and exceptions (because they never **return** a value<SideNote id="technicalities">Technicalities like this are extremely important in understanding a type system</SideNote>) are represented by `never`.

`never` also shows up when you have a union of finite possibilities, and an if/else or switch that exhausts those possibilities ("process of elimination") and there's still a branch of code left over. That branch of code can never be hit, so the type of the variable is narrowed to never.

```typescript
type Color = 'blue' | 'green'
declare const color: Color
switch (color) {
  case 'blue':
    break
  case 'green':
    break
  default: {
    console.log('yeah nah', color)
    //                       ^?    never
  }
}
```

The TypeScript documentation describes the `never` type in the page for [Functions](https://www.typescriptlang.org/docs/handbook/2/functions.html#never) which is an interesting choice. A thorough explanation is here: [A complete guide to TypeScript's never type](https://www.zhenghao.io/posts/ts-never).

</NewConcept>

## Testing

This is a good time to pause for some tests. The code below is placed in a summary/details because it's fairly long, and because you can skip this section if you just want to get to the rest of the tutorial<SideNote id="write-tests">but you probably should write tests of some kind</SideNote>.

As mentioned in the introduction, I'm using [vitest](https://vitest.dev/). This lets me write my tests directly next to the code that it's testing, which I really like<SideNote id="adjacent-test">I used to think this was weird, then I tried it, and I don't think it's weird anymore</SideNote>.

Additionally, I'm using the tips from [Total TypeScript](https://www.totaltypescript.com/how-to-test-your-types) on how to test your types. Yes, you read that correctly! Remember that we're writing code for two contexts, the type context and the value context, it's important that we test both contexts. The nice thing about testing types is that a failing test is shown as a compiler error so you get feedback even faster than traditional tests.

<Spoiler summary="example test setup">

For each of the built-in shapes so far, we test both the `decode` function and the `Infer<Shape>` type for that shape.

```typescript
if (import.meta.vitest) {
  const { test, expect, describe } = import.meta.vitest

  // https://www.totaltypescript.com/how-to-test-your-types
  type Expect<T extends true> = T
  // prettier-ignore
  // eslint-disable-next-line @typescript-eslint/no-unnecessary-type-parameters
  type Equal<X, Y> = (<T>() => T extends X ? 1 : 2) extends (<T>() => T extends Y ? 1 : 2)
      ? true
      : false

  describe('Unknown', () => {
    test('Unknown decoding', () => {
      expect(unknown.decode('no idea')).toStrictEqual('no idea')

      type Expected = unknown
      type Actual = Infer<typeof unknown>
      type _Test = Expect<Equal<Expected, Actual>>
    })
  })

  describe('Boolean', () => {
    test('Boolean decoding', () => {
      expect(boolean.decode(true)).toStrictEqual(true)
      expect(boolean.decode(false)).toStrictEqual(false)

      type Expected = boolean
      type Actual = Infer<typeof boolean>
      type _Test = Expect<Equal<Expected, Actual>>
    })
  })

  describe('Number', () => {
    test('Number decoding', () => {
      expect(number.decode(16)).toStrictEqual(16)
      expect(number.decode(0)).toStrictEqual(0)
      expect(number.decode(-0)).toStrictEqual(-0)
      expect(number.decode(-16)).toStrictEqual(-16)

      type Expected = number
      type Actual = Infer<typeof number>
      type _Test = Expect<Equal<Expected, Actual>>
    })
  })

  describe('String', () => {
    test('String decoding', () => {
      expect(string.decode('')).toStrictEqual('')
      expect(string.decode('hello')).toStrictEqual('hello')

      type Expected = string
      type Actual = Infer<typeof string>
      type _Test = Expect<Equal<Expected, Actual>>
    })
  })
```

</Spoiler>

## Collection types - Array

We're going to start increasing the complexity now. Users of our library are going to want to be able to use **collections**, meaning they can `decode` more than one value at a time.

The two kinds of collections that we'll support are:

- **Arrays**: an ordered sequence of values of the same shape
- **Records**: a set of key-value pairs where the keys are strings and the values are the same shape

In TypeScript, these are written as `T[]` (or `Array<T>`, it's the same thing) and `Record<string, T>`, respectively.

Array is slightly less complicated than records, so we'll start there.

```typescript
interface ShapeArray<S extends Shape<unknown>> extends Shape<Infer<S>[]> {
  readonly __tag: 'array'
}
```

Our new `ShapeArray` type has a type parameter, which we've seen before. It also `extends` another type, which we've also seen before. What's a bit new is the type that it is extending is, itself, a type with a parameter. It's like calling a function that calls another function.

Just like functions can call themselves (recursion), types can also "call" themselves. The same rules that we all learned about recursion still apply, you need both the recursive case(s) and base case(s) to escape the recursion. We already have those base cases, which are the primitive types defined earlier, so we can add a recursive case.

{/* prettier-ignore */}
```typescript
export type Infer<S extends Shape<unknown>> = S extends ShapeUnknown
  ? unknown
  : S extends ShapeBoolean
    ? boolean
    : S extends ShapeNumber
      ? number
      : S extends ShapeString
        ? string
        : S extends ShapeBigInt
          ? bigint
          : S extends ShapeArray<infer ElementShape>
            ? Infer<ElementShape>[]
            : never
```

<NewConcept title="`infer` keyword">

A new keyword! This is described in the TypeScript handbook in [Inferring Within Conditional Types](https://www.typescriptlang.org/docs/handbook/2/conditional-types.html#inferring-within-conditional-types).

It helped me to understand this by converting this into imperative (pseudo)code, to get a sense of what's happening in this type-level code:

```typescript
// this ain't real code
if (S is ShapeArray) {
  // could also be thought of as "unwrapping" the type to get
  // the delicious insides
  let ElementShape = ShapeArray[0]

  // remember capital-I `Infer` is like a function that you
  // pass in a type and it gives you back a type
  return Array.of(Infer(ElementShape))
}
```

If `S` is (a subtype of) `ShapeArray<T>`, then the `infer` keyword makes a NEW type variable, which we're allowed to use in the 'true' branch.

```typescript
// ...snip...
  : S extends ShapeArray<infer ElementShape>
  //                     ^^^^^^^^^^^^^^^^^^ defines a NEW
  //                     type variable called `ElementShape`
    ? Infer<ElementShape>[]
    //      ^^^^^^^^^^^^ We can use this in the 'true' branch
    : never
```

For my Rustaceans out there, it reminds me of `if let` pattern matching:

```rust
// rust 🦀🦀🦀

if let Some(data) = maybeData {
  //        ^^^^ defines a NEW variable called `data`
  use_the_data(data)
  //           ^^^^ We can use this NEW variable in the 'true' branch
}
```

</NewConcept>

<KnowledgeCheck>

Based on the concepts introduced so far, create a type called `GetElementType` which takes an Array type as its parameter and returns the type of the elements of that Array.

For example:

- given `string[]` it should return `string`
- given `number[][]` it should return `number[]`

Try it yourself, then check the spoiler below.

<Spoiler summary="answer">

```typescript
type GetElementType<Arr extends unknown[]> = Arr extends Array<infer T> ? T : never

type Test1 = GetElementType<string[]>
//    ^?   = string

type Test2 = GetElementType<number[][]>
//    ^?   = number[]

// etc.
```

Some additional notes:

1. The first `extends` constrains the type parameter to be only Arrays
2. The second `extends` is necessary to use the `infer` keyword to pull out the inner type
3. Only the true branch will ever be hit. The `never` type is used for the false branch because we already constrained the type parameter to be an array

Remember that the `extends` keyword is really more like two different keywords, depending on whether its used as a **constraint** vs. a **conditional** type.

</Spoiler>

A practical usage of this concept is getting the inner type `T` out of a defined `FormGroup<T>` in the Angular framework.

</KnowledgeCheck>

Now it's time to implement the built-in shape that we will provide to users for arrays. The previous shapes were implemented as object literals, but there's something new/different this time, which is that users will need to make "Array of ShapeNumber" or "Array of ShapeString" or "Array of Array of ShapeBoolean", etc. So instead of an object literal, we need to implement it as a **function** that returns the shape.

```typescript
function array<S extends Shape<unknown>>(elementShape: S): ShapeArray<S> {
  return {
    __tag: 'array',
    decode(input: unknown): Infer<S>[] {
      if (!Array.isArray(input)) {
        throw new Error('oopsy whoopsy!')
      }

      return input.map(elementShape.decode) as Infer<S>[]
    },
  }
}
```

When decoding the incoming data, we first check if the incoming data is an array, and error if not<MarginNote id="array-is-array">Sadly, `Array.isArray` produces `any[]` rather than `unknown[]`, so we have to "[just](https://www.todepond.com/wikiblogarden/better-computing/just/) be careful" with the output, or maybe change it to `unknown[]` via assertion to remove some potential for issues</MarginNote>. Then, decodes every element of the array using the provided shape (both transforming and validating).

The decode function returns `Infer<S>[]` which is "an array of the inferred type of the provided shape". So if the provided shape was `ShapeNumber`, then it returns `number[]`. Our `Infer<Shape>` type is already recursive, so this already handles nested arrays automatically.

Note the usage of the [type assertion](https://www.typescriptlang.org/docs/handbook/2/everyday-types.html#type-assertions). This is typically something to **avoid using** when possible. However, this is a rule to selectively break when practical. There might be a clever way with advanced TypeScript features to avoid this assertion (or something obvious that I've simply missed), but in cases like this I think it's appropriate to use an assertion.

Keep in mind also that more code in the type context is more code that needs to be run by the compiler every time it does type checking (including in your IDE/language server). Assertions can be a way to reduce this, though I don't know how to (or if it's possible to) run benchmarks of the compiler itself to see if this is an issue in reality.

We should add tests for this built-in shape - try it yourself, and feel free to take a look at the examples in the spoiler below as well.

<Spoiler summary="example 'array' tests">

```typescript
describe('Array', () => {
  test('Array decoding', () => {
    const StringArray = array(string)

    expect(StringArray.decode(['a', 'b', 'c'])).toStrictEqual(['a', 'b', 'c'])

    type Expected = string[]
    type Actual = Infer<typeof StringArray>
    type _Test = Expect<Equal<Expected, Actual>>
  })

  test('nested Array decoding', () => {
    const StringArrayArray = array(array(string))

    expect(
      StringArrayArray.decode([
        ['a', 'b'],
        ['c', 'd'],
        ['e', 'f'],
      ])
    ).toStrictEqual([
      ['a', 'b'],
      ['c', 'd'],
      ['e', 'f'],
    ])

    type Expected = string[][]
    type Actual = Infer<typeof StringArrayArray>
    type _Test = Expect<Equal<Expected, Actual>>
  })
})
```

</Spoiler>

## Collection types - Record

Records are similar to Arrays, based on our definition of the term which aligns to the [TypeScript utility type](https://www.typescriptlang.org/docs/handbook/utility-types.html#recordkeys-type) of the same name. We're defining this as a collection of zero-to-many key/value pairs, where the keys are strings and the values are all of the same shape.

We define the built-in shape very similarly to `ShapeArray`:

```typescript
interface ShapeRecord<S extends Shape<unknown>> extends Shape<Record<string, Infer<S>>> {
  readonly __tag: 'record'
}
```

This means the `decode` function will return `Record<string, Infer<S>>` meaning that if the user passes in `ShapeNumber`, it will return `Record<string, number>`.

Then we mechanically add another case to the `Infer<Shape>` type (getting bored yet?):

{/* prettier-ignore */}
```typescript
export type Infer<S extends Shape<unknown>> = S extends ShapeUnknown
// ...snip...
            : S extends ShapeRecord<infer ValueShape>
              ? Record<string, Infer<ValueShape>>
              : never
```

The implementation for Record is only slightly more interesting than Array because:

1. The `typeof null === 'object' [<del>bug</del> feature](https://2ality.com/2013/10/typeof-null.html) means we need a truthy check first
2. JavaScript doesn't provide a single-step way to map from one object to another, so we need to do this little dance with `Object.fromEntries` and `Object.entries`<SideNote id="objects-as-data">There's complications with having a built-in for this, such as how to handle prototype inheritance, non-enumerable properties, configurable properties, proxies (?), encapsulation, and probably a bunch of other edge cases. The fundamental language design complication is [conflating objects and data](https://dpc.pw/posts/data-vs-code-aka-objects-oop-conflation-and-confusion/) as the same thing</SideNote>

```typescript
function record<S extends Shape<unknown>>(valueShape: S): ShapeRecord<S> {
  return {
    __tag: 'record',
    decode(input: unknown): Record<string, Infer<S>> {
      if (!input || typeof input !== 'object' || Array.isArray(input)) {
        throw new Error('oopsy whoopsy!')
      }

      return Object.fromEntries(
        Object.entries(input).map(([key, value]) => [key, valueShape.decode(value) as Infer<S>])
      )
    },
  }
}
```

Besides those additional wrinkles, it's the same as `array` where it recursively decodes the inner values into the desired shape (or error).

<KnowledgeCheck>

Should we have used the built-in [Map](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map) to represent this? Why or why not? How would you implement `decode` to transform input data that was a plain object **into** a Map if you decided to go this route?

Bonus knowledge check: Why didn't TypeScript define the `Record` utility type to use the built-in `Map`?

</KnowledgeCheck>

Tests! Test test test test. Here's some example tests if you please:

<Spoiler summary="example 'record' tests">

```typescript
describe('Record', () => {
  test('Record decoding', () => {
    const StringRecord = record(string)

    expect(StringRecord.decode({ a: 'aa', b: 'bb' })).toStrictEqual({
      a: 'aa',
      b: 'bb',
    })

    type Expected = Record<string, string>
    type Actual = Infer<typeof StringRecord>
    type _Test = Expect<Equal<Expected, Actual>>
  })

  test('nested Record decoding', () => {
    const StringRecordRecord = record(record(string))

    expect(StringRecordRecord.decode({ a: { aa: 'aaa' }, b: { bb: 'bbb' } })).toStrictEqual({
      a: { aa: 'aaa' },
      b: { bb: 'bbb' },
    })

    type Expected = Record<string, Record<string, string>>
    type Actual = Infer<typeof StringRecordRecord>
    type _Test = Expect<Equal<Expected, Actual>>
  })
})
```

</Spoiler>

<KnowledgeCheck>

We had to implement `array` and `record` as functions because the user needs to pass in the inner shape.

Should we also have implemented `boolean`/`number`/`string` as functions? Is there a scenario where we'd want people to pass in anything extra?

<Spoiler summary="ideas">

There's no "right" or "wrong" answer here, it's a matter of design. We could have implemented these as functions so that users could add (optional) constraints on these built-in shapes, such as:

```typescript
const NonEmptyString = string({ minLength: 1 })
const BigNumber = number({ min: 100 }) // 100 is as high as I can count, so it must be big
```

That would require our built-ins to be a function. We also could probably figure out a way to make it like this instead:

```typescript
const NonEmptyString = string.minLength(1)
const BigNumber = number.min(101) // I learned how to count the next number
```

and maybe these would not need to be functions. But we might make them functions anyways so that they're all homogenous. Choices choices!

</Spoiler>

</KnowledgeCheck>

## Shapey Shapes - struct

This is going to be the most complicated shape... so far!

Our `struct` is a set of key and value pairs like a record, but differs from `record`:

- A record has zero-to-many key/value pairs, a struct has exactly as many key/values as are defined by the user
- A record has keys that aren't known, a struct has keys that are known (as defined by the user)
- A record has a single shape for all the values, a struct may have a different shape for each value (as defined by the user)

At runtime, these are both JavaScript objects, but we're making the distinction at compiletime in the type context.

To implement the type, let's remind ourselves of what users will need to pass into our shapes to produce their custom shapes:

- `unknown`, `boolean`, `number`, `string`, `bigint`: users pass in nothing, no parameters needed
- `array`, `record`: users pass in ONE shape, since these are homogenous collections
- `struct`: users pass in a **record**<SideNote id="record-first">This is why we did `record` before `struct`!</SideNote> of key/shape pairs to define their struct

What does that look like in code?

```typescript
type StructFields = Record<string, Shape<unknown>>

interface ShapeStruct<Fields extends StructFields> extends Shape<InferStruct<Fields>> {
  readonly __tag: 'struct'
}
```

We extracted out `StructFields` and `InferStruct` to improve readability, similar to how you'd extract out a variable or function. The implementation of `InferStruct` is a little bit of a doozy:

```typescript
type InferStruct<Fields extends StructFields> = {
  [Key in keyof Fields]: Infer<Fields[Key]>
}
```

<NewConcept title="`keyof` operator">

The [keyof operator](https://www.typescriptlang.org/docs/handbook/2/keyof-types.html) is a unary operator in the type context, similar to the `typeof` operator (the type context one, not the value context one), t. Its argument is **object type**, and it returns a union type of the keys of that object.

```typescript
type ConfigOptions = { dryRun: boolean; logLevel: LogLevel; apiKey: string }

type ConfigOptionName = keyof ConfigOptions // 'dryRun' | 'logLevel' | 'apiKey'
```

</NewConcept>

<KnowledgeCheck>

What happens if you use the `keyof` type operator on an array type?

</KnowledgeCheck>

<NewConcept title="indexed accessed types">

[Indexed Accessed Types](https://www.typescriptlang.org/docs/handbook/2/indexed-access-types.html) are types that can be accessed by index! How about that!<MarginNote id="losing-decorum">I'm losing my decorum as we approach the end of this tutorial</MarginNote>. The indexing uses square brackets `[]` in the type context, using the same syntax as how you index into things in the value context.

The part of the code above using this feature is `Fields[Key]`. You can index into an object type or an array type, and the key that you use for the indexing can be a `string`, `number`, or a union of strings and/or numbers.

</NewConcept>

Like before, I think it can be helpful to imagine an imperative (pseudo)code of this more complicated type code. For example, this `InferStruct<Fields>` generic type can be thought of like:

```typescript
// this ain't real code
function InferStruct(fields: Record<string, Shape<unknown>>) {
  let returnType = {}
  let keys = Object.keys(fields)

  for (const key in keys) {
    returnType[key] = Infer(fields[key])
  }
  return returnType
}
```

So the type code before, the part with the `in` keyword, is like a loop that takes the key/values from the input object (type) and maps those to an output object (type). This loop runs at compiletime or in your IDE whenever type checking is done.

Oops! Almost forgot<MarginNote id="almost-forgot">Well, I actually did forget until I wrote the type tests and they failed, but since this isn't live you'd never know!</MarginNote>, we need to mechanically add another case to our `Infer<Shape>` type.

{/* prettier-ignore */}
```typescript
export type Infer<S extends Shape<unknown>> = S extends ShapeUnknown
// ...snip...
            : S extends ShapeStruct<infer Fields>
              ? InferStruct<Fields>
              : never
```

Let's implement the `decode` function for this shape. The runtime code (value context) is quite similar to `record` because these **are** the same thing at runtime in the value context. The distinction between these two shapes is really a compile-time distinction in the type context.

```typescript
const UnknownRecord = record(unknown)

function struct<Fields extends StructFields>(fieldShapes: Fields): ShapeStruct<Fields> {
  return {
    __tag: 'struct',
    decode(input: unknown): InferStruct<Fields> {
      const inputRecord = UnknownRecord.decode(input)

      return Object.fromEntries(
        Object.entries(fieldShapes).map(([key, shape]) => [key, shape.decode(inputRecord[key])])
      ) as InferStruct<Fields>
    },
  }
}
```

We can reuse the decoding for `record` to first make sure the runtime object at least satisfies that shape, then we check that each of these fields correspond to the specifically defined shape for that field.

<KnowledgeCheck>

Reusing the `record` decoder means that we are looping through the key/values of the runtime object twice, once for record and once for struct. If this ever becomes a legitimate performance concern (with performance benchmark evidence), then this could be refactored to only loop once.

</KnowledgeCheck>

Don't forget tests!

<Spoiler summary="example 'struct' tests">

Some example tests that you could add. Feel free to change it and/or add your own!

```typescript
describe('Struct', () => {
  test('Struct decoding', () => {
    const Point = struct({
      x: number,
      y: number,
    })

    expect(Point.decode({ x: 1, y: 2 })).toStrictEqual({ x: 1, y: 2 })

    type Expected = {
      x: number
      y: number
    }
    type Actual = Infer<typeof Point>

    type _Test = Expect<Equal<Expected, Actual>>
  })

  test('nested Struct decoding', () => {
    const Point = struct({
      x: number,
      y: number,
    })
    const NestedPoint = struct({
      start: Point,
      end: Point,
    })

    expect(NestedPoint.decode({ start: { x: 1, y: 2 }, end: { x: 10, y: 20 } })).toStrictEqual({
      start: { x: 1, y: 2 },
      end: { x: 10, y: 20 },
    })

    type Expected = {
      start: {
        x: number
        y: number
      }
      end: {
        x: number
        y: number
      }
    }
    type Actual = Infer<typeof NestedPoint>

    type _Test = Expect<Equal<Expected, Actual>>
  })

  test('Struct type inference', () => {
    expect(true).toBe(true)

    type Expected = {
      n: number
      s: string
      a: boolean[]
      r: Record<string, number>
    }
    type Actual = InferStruct<{
      n: ShapeNumber
      s: ShapeString
      a: ShapeArray<ShapeBoolean>
      r: ShapeRecord<ShapeNumber>
    }>

    type _Test = Expect<Equal<Expected, Actual>>
  })
})
```

</Spoiler>

## Shapey Shapes - Unions (tagged)

The final shape we'll implement is [tagged unions](https://en.wikipedia.org/wiki/Tagged_union), also known as discriminated unions.

<EmphasisBox>

You could actually stop here if you want, what we have so far is surprisingly usable (besides the poor error handling, which will be addressed in the next article). Oh, and what we have so far completely doesn't handle optional fields 😬 (which _might_ be addressed in a future article, depending on how much energy I have, but it might be an "exercise for the reader").

I do think this tagged unions is quite an interesting and messy topic in TypeScript.

</EmphasisBox>

The TypeScript documentation for discriminated unions is located on the page about [Narrowing](https://www.typescriptlang.org/docs/handbook/2/narrowing.html#discriminated-unions).

Tagged/discriminated unions are a set of _variants_, where the data can be **exactly one** of those variants (not multiple, not zero, exactly one and only one). Every time you describe business logic and use the word "or", that could be modeled by a tagged union. Every flow chart with a choice point where one path becomes two or more paths could be modeled by a tagged union<MarginNote id="struct-union">A struct type represents "AND", a tagged union represents "OR"</MarginNote>.

The TypeScript documentation provides this as an example of a discriminated union (paraphactored by yours truly):

{/* prettier-ignore */}
```typescript
type Shape = 
  | { kind: 'circle', radius: number } 
  | { kind: 'square', sideLength: number }
```

The field "kind" is the _discriminant_, meaning that this field is used to _discriminate_ (distinguish) between which variant is this data. There's nothing special about the word "kind" used as the field name, the field could be named "babaganoush" and it would still be treated as the discriminant. How is that possible? The TypeScript compiler uses heuristics to essentially _guess_ what the discriminant is. When you look at other languages that have tagged unions built-in to the language, there's no guessing involved because the tag has a different syntax than the rest of the fields.

<Spoiler summary="examples from other languages">

OCaml:

```ocaml
type circle = { radius: float }
type square = { side_length: float }
type shape =
    | Circle of circle
    | Square of square
```

Rust:

```rust
enum Shape {
  Circle { radius: f64 },
  Square { side_length: f64 },
}
```

Swift:

```swift
struct Circle { var radius: float }
struct Square { var sideLength: float }
enum Shape {
  case circle(Circle)
  case square(Square)
}
```

In each of these languages, the tag/discriminant is **separate** from the data of each variant, and so is syntactically distinct. In TypeScript, the tag/discriminant lives inside the object and is determined by heuristics.

</Spoiler>

There's another syntax for discriminated unions that the documentation doesn't tell you about:

{/* prettier-ignore */}
```typescript
type Shape = 
  | ['circle', { radius: number }] 
  | ['square', { sideLength: number }]

declare const shape: Shape

switch (shape[0]) {
  case 'circle': {
    console.log(shape[1].radius)
    //                   ^^^^^^ OK
    break
  }
  case 'square': {
    console.log(shape[1].sideLength)
    //                   ^^^^^^^^^^ OK
    break
  }
}
```

Instead of an object with a key as the discriminant (determined by heuristics), you can use variants of arrays where the first element is the discriminant<SideNote id="array-discriminant">It actually doesn't have to be the first element either. If you switch the order and indexes in the example above, it still works. So is there a limit? Could it be the 999th element? It's not documented</SideNote>. After checking the discriminant, you can use the associated variant data in each branch.

It gets better! There can actually be **multiple discriminants** in each variant! I didn't even know this was possible until [logging an issue](https://github.com/microsoft/TypeScript/issues/52358) to improve an error message, that ended up being related to multiple discriminants (this is now fixed).

This isn't some wild tangent. As a library author, if you want to support discriminated unions, you need to know all of these fine details and decide exactly what you want to support.

For the purpose of this tutorial, we are only going to implement the array version with a single discriminant that must be a string in the first element position. Whether that's useful or not could be measured by how many GitHub issues are logged for our library asking for more options with tagged unions.

With these restrictions in place, it's not much different than the struct definition:

```typescript
type UnionVariants = Record<string, Shape<unknown>>

interface ShapeUnion<Variants extends UnionVariants> extends Shape<InferUnion<Variants>> {
  readonly __tag: 'union'
}
```

Where `InferUnion<Variants>` is also similar:

```typescript
type InferUnion<Variants extends UnionVariants> = {
  [Key in keyof Variants]: [Key, Infer<Variants[Key]>]
}[keyof Variants]
```

The two important differences between this and the previous shape is the wrapping in an array with the key as the first element - the `[Key, Infer<Variants[Key]>]` part. The second difference is the whole object type generated is then indexed into - the `[keyof Variants]` part. So this type has two examples of indexed access here.

The implementation of the decoder is fairly different from `record` though. We expect the runtime value to be a 2-element array with the first element being the tag and the 2nd element being the data. In the happy path, we find the appropriate variant using the tag, and decode the data with the appropriate shape for that tag.

```typescript
function union<Variants extends UnionVariants>(variants: Variants): ShapeUnion<Variants> {
  return {
    __tag: 'union',
    decode(input: unknown): InferUnion<Variants> {
      if (!Array.isArray(input) || input.length !== 2) {
        throw new Error('oopsy whoopsy!')
      }

      const [tag, value] = input as [unknown, unknown]

      if (typeof tag !== 'string' || !Object.keys(variants).includes(tag)) {
        throw new Error('oopsy whoopsy!')
      }

      return [tag, variants[tag].decode(value) as Infer<Variants[typeof tag]>]
    },
  }
}
```

We need the type assertion to `[unknown, unknown]` because TypeScript doesn't track array lengths at compiletime. So unlike some other cases of [narrowing](https://www.typescriptlang.org/docs/handbook/2/narrowing.html), where by doing `if` checks you can narrow the type, checking for `.length === 2` doesn't narrow `unknown[]` to `[unknown, unknown]`, you have to assert it yourself<MarginNote id="dependently-typed-languages">If this sounds like an interesting research topic, look up [dependently typed languages](https://en.wikipedia.org/wiki/Category:Dependently_typed_languages)!</MarginNote>. We need the second type assertion for the same reason described earlier, we're using the assertion for the intended purpose which is to have the compiler trust us for something that we're proving with runtime checking outside the capabilities of the type checker.

Oh yeah, some tests too:

<Spoiler summary="example 'union' tests">

```typescript
describe('Union', () => {
  test('Union decoding', () => {
    const NumOrStr = union({
      num: number,
      str: string,
    })

    expect(NumOrStr.decode(['num', 16])).toStrictEqual(['num', 16])
    expect(NumOrStr.decode(['str', 'hello'])).toStrictEqual(['str', 'hello'])

    type Expected = ['num', number] | ['str', string]
    type Actual = Infer<typeof NumOrStr>

    type _Test = Expect<Equal<Expected, Actual>>
  })

  test('nested Union decoding', () => {
    const Point = struct({
      x: number,
      y: number,
    })
    const ClickEvent = struct({
      point: Point,
      isDoubleClick: boolean,
    })
    const DragEvent = struct({
      start: Point,
      end: Point,
      duration: number,
    })
    const MouseEvent = union({
      click: ClickEvent,
      drag: DragEvent,
    })

    expect(
      MouseEvent.decode(['click', { isDoubleClick: false, point: { x: 100, y: 200 } }])
    ).toStrictEqual(['click', { isDoubleClick: false, point: { x: 100, y: 200 } }])

    type Expected = ['click', Infer<typeof ClickEvent>] | ['drag', Infer<typeof DragEvent>]
    type Actual = Infer<typeof MouseEvent>

    type _Test = Expect<Equal<Expected, Actual>>
  })

  test('Union type inference', () => {
    expect(true).toBe(true)

    type Expected = ['x', number] | ['s', string] | ['a', boolean[]] | ['r', Record<string, number>]

    type Actual = InferUnion<{
      x: ShapeNumber
      s: ShapeString
      a: ShapeArray<ShapeBoolean>
      r: ShapeRecord<ShapeNumber>
    }>

    type _Test = Expect<Equal<Expected, Actual>>
  })
})
```

</Spoiler>

## Conclusion

Made it to the end! Thank you for staying with me so far.

Up next will be Part 2 and Part 3. In Part 2<SideNote id='hopefully-shorter'>Which is **hopefully** shorter</SideNote> we'll provide the capability for users to define their own custom decoders and explain why this is good, and we'll fix the error handling in the decoding. In Part 3 we'll implement encoding and finish out any other odds and ends.

There's more in the Appendix below that's recommended and Part 2 and 3 will assume that this code has been followed. However, it's not strictly necessary for the functioning of the library so it's moved down there.

Stay tuned and see you in the next one!

## Appendix

### Exercise - Abstraction for mandatory decoding of HTTP responses

The TypeScript type system is intentionally designed with holes in it via the `any` annotation (whether implicitly or explicitly). Some common holes that let non-statically typed data into our applications are [JSON.parse](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/parse), [Request.json](https://developer.mozilla.org/en-US/docs/Web/API/Request/json), among others.

<KnowledgeCheck>

Write a wrapper around the native [fetch]() function that requires a shape to be passed in, and returns the decoded type from that shape (assume JSON format).

An example use case of your `myFetch` function could be something like this:

```typescript
const Point = struct({ x: number, y: number })
type Point = Infer<typeof Point>

const point = await myFetch('/some/url', Point)
//    ^^^^^ this should be type Point and was decoded properly
```

</KnowledgeCheck>

### Exercise - Constraining `Shape` further

Our definition of `Shape` allowed for any string in the `__tag` field, and then our big conditional branch for `Infer<Shape>` assumed `never` at the end if the tag didn't match. That works fine, because if someone passed in a shape with an invalid tag to `Infer<Shape>`, then they would get `never` as the result which they can't do anything with.

This isn't likely to happen, because users are going to be using our provided shape-building functions, which all use valid tags. Still, if someone really wants to (or just makes an honest mistake), we can make the experience a little better by explicitly listing out which tags are allowed.

```typescript
type ShapeTag =
  | 'unknown'
  | 'boolean'
  | 'number'
  | 'string'
  | 'bigint'
  | 'array'
  | 'record'
  | 'struct'
  | 'union'

interface Shape<T> {
  readonly __tag: ShapeTag
  readonly decode: (input: unknown) => T
}
```

Now, there will be a compiler error at the `Infer` call itself if an invalid shape is passed in, rather than no error and producing a `never` result.

### Conceptual - Do we need a runtime value for the tag?

Do we need a runtime value for the tag, when it's never checked or used at runtime?

The short answer is yes, and it's by design of the TypeScript type system (you could argue it's a feature or it's a limitation). We could try to convert this to only a type parameter, but TypeScript doesn't properly check it in that case. There's no equivalent to [phantom type parameters](https://doc.rust-lang.org/rust-by-example/generics/phantom.html) which are only checked at compiletime and don't exist at runtime. If we made a type parameter that wasn't used in the runtime object, it appears that TypeScript defaults this type parameter to `{}` when checking conditional type constraints.

i.e. if you were to try to do this so that `Tag` only existed in the type context (with the appropriate refactoring elsewhere), it wouldn't work:

```typescript
interface Shape<T, Tag extends ShapeTag> {
  readonly decode: (input: unknown) => T
}
```

In this case, `Tag` would be defaulted to `{}` and it wouldn't be used properly in downstream `extends` checks.

<KnowledgeCheck>

What does `{}` mean in the type system?

Hint: It does **not** mean "empty object".

</KnowledgeCheck>

### Vocabulary - Decoding vs. Parsing vs. Deserializing vs. Marshalling

I chose not to use the terminology _parsing_, although it definitely fits, simply because there isn't a good opposite word ("unparsing", "deparsing", etc. sounds silly). Decoding and encoding has a nice symmetry.

_Deserializing_ is a pretty good synonym as well, but it implies that the input data is in a "primitive" format such as a byte stream or a string. Our decoder does not have this restriction, in fact, many of our built-in shapes work on input data that is already a JavaScript object of some kind.

Marshalling just sounds weird to me for some reason, I don't know why.

### Exercise - Union of String Literals

It's pretty common to see TypeScript types like this:

```typescript
type Color = 'red' | 'green' | 'blue'
```

It's especially common to see this in data that's close to the boundary of the program, because serialization and deserialization is easy when it's a plain string (or plain number) compared to a TypeScript `enum` which is a runtime object.

How would you support this? If you think about it, it's similar to our existing (tagged) `union` shape except there's only a tag and no associated data. Would you add this use case to this existing shape or make a new shape?

Try implementing it, and see what additional questions come up.

export default function TsIoDecodingEncoding1({ children }) {
  return <ArticlePage meta={meta}>{children}</ArticlePage>
}
