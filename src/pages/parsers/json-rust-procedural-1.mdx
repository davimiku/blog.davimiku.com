export const meta = {
  title: 'Tutorial: Writing a JSON Parser (Rust) - Part 1/2',
  category: 'parsers',
  type: 'tutorial',
  slug: 'json-rust-procedural-1',
  tagline: 'Learn the fundamentals of parsing by building a JSON parser from scratch',
  tags: ['JSON', 'Rust'],
  publishedOn: '2023-06-10',
}

import { BlogsPage } from '../../layouts/blog'
import { EmphasisBox, NewConcept, Spoiler } from '../../components/blog'

<EmphasisBox>

**Intended Audience**:

- People who would like to learn about parsing
- Anyone who wants a hands-on gentle introduction to the Rust programming language

**Recommended Proficiency Level**:

- Comfortable with any statically typed language and familiar with a terminal / command line
- No Rust experience is needed!

**Learning Method**:

This is a hands-on tutorial, just reading through won't get you much. You'll get the most out of it by actually firing up a code editor and following along!

</EmphasisBox>

## Introduction

In this tutorial, we will learn how to write a JSON parser from scratch, using the [Rust programming language](https://www.rust-lang.org/).

We will create a [library](<https://en.wikipedia.org/wiki/Library_(computing)>), so that users of our library can pass in the JSON string and they'll receive back parsed JSON.

This is a two part series:

1. Recursive Descent (top-down) - This article!
2. Parser Combinators (bottom-up) - Not written yet

The code for this article uses a **procedural/imperative** style, and should be familiar for anyone coming from languages using those styles. We won't get into advanced Rust features, and every new concept will be explained in detail.

To understand "JSON parser", we'll first ensure we understand "JSON" and "parser" in the next sections.

### What is JSON?

JavaScript Object Notation ([JSON](https://www.json.org)) is a format for exchanging and storing data. As the name implies, the syntax is based on JavaScript, but it is a language-independent data format.

The possible data types in JSON are fixed (a _closed set_), meaning that the format itself is not extensible. There are exactly six possible data types that can be transmitted via JSON, also described in the previous link.

1. `null`
2. boolean: `true` or `false`
3. string: `"a string"`
4. number: `2`, `-2`, `2.5`, `2E+32`, `2e-16`
5. array: `[ json_value, json_value, ... ]`
6. object: `{ "key": json_value, ... }`

The "array" and "object" types are **recursive** - they contain other JSON values.

<Spoiler summary="Edge case: JSON syntax as a subset of Javascript syntax">

Until JavaScript's 2019 edition (ES2019), JSON syntax was _almost_ a subset of JavaScript syntax. There was one edge case -- JSON strings could contain the Unicode characters U+2028 (LINE SEPARATOR) and U+2029 (PARAGRAPH SEPARATOR) unescaped while in JavaScript they had to be escaped.

This means that valid JSON might not be valid JavaScript, which breaks that subset relationship. As of ES2019, with the approval and implementation of the [json-superset proposal](https://github.com/tc39/proposal-json-superset) proposal, JSON syntax is now a proper subset of JavaScript syntax.

</Spoiler>

<Spoiler summary="Edge case: Are JSON semantics a subset of JavaScript semantics?">

Although JSON is a **syntactic** subset of JavaScript, it is not necessarily a **semantic** subset of Javascript. For example, the following produces a different result when parsed as Javascript vs. JSON.

```javascript
const str = `[{ "__proto__": [] }]`

const fromJS = eval(str)
const fromJSON = JSON.parse(str)
```

The `fromJS` result is an array with one item, where that item is an Object that has Array as its prototype.
The `fromJSON` result is also an array with one item, and that item is an Object who has an own property with
an identifier of `__proto__` (you can run this code in your browser console and compare the result of `Object.getOwnPropertyNames(x)` for `fromJS` and `fromJSON`).

Edge cases are weird, right?

</Spoiler>

### What is Parsing?

In programming, "parsing" is transforming less-structured input into more-structured output by applying knowledge of the expected shape(s) of the data. A "parser" is a function that does this. By definition, this transformation might fail if the input isn't compatible with the desired output.

This is a fairly flexible interpretation, and perhaps a little vague, so some breakdown on the statement above:

- _less-structured input_ examples:
  - A `String` is a common input format for text-based data, which is a sequence of characters (what is a "character"? An entire article could be written on this)
  - A stream of bytes is also unstructured input, for example audio data that is parsed by some audio player program
- _more-structured output_ examples:
  - JSON structure - rather than a flat sequence of characters, it now has an organized representation with the six data variants discussed in the Introduction.
  - HTTP request - An incoming HTTP request is a stream of bytes, but it can be parsed into a more-structured representation that has the method, path, protocol, headers, body, etc.
- _knowledge of the expected shape_:
  - We can't parse a less-structured input without knowing what it possibly could be.
  - We apply that knowledge when parsing, to check if the input adheres to the expected shape
- _might fail_:
  - If the input doesn't align to the expectations, then the parsing fails
  - Example: If the incoming String is not in JSON format, then it is not JSON and the parsing fails
  - Example: If the incoming POST data to the `/api/invoice` endpoint does not have the fields defined for an `Invoice`, then it is not an `Invoice` and parsing fails
  - Parsing failures are **not exceptional**. Any time we deal with data from the outside world, the possibility of parsing failure is as equally plausible as parsing success.

## Project Setup

Enough talk, let's get started!

### Development Environment Setup

The Rust compiler is available on all popular operating systems. If you don't already have it installed, head over to [rust-lang.org](https://www.rust-lang.org/) and follow the instructions to get started for your operating system. This setup page also has links to activating Rust support in various code editors/IDE.

Personally, I use Visual Studio Code (VS Code) running in Windows Subsystem for Linux (WSL), but this tutorial can be followed on any operating system and code editor that Rust supports.

### Project Setup

We're going to create a _library_ for our JSON parser. In your command line, navigate to the directory where you want this project to exist. For example: `~/tutorials/rust`. Run the following command to generate a new Rust library project:

```
cargo new --lib json_parser
```

This creates a new folder, `json_parser`, that contains the new Rust project.

<Spoiler summary="Why create a library?">

From the [documentation for `cargo new`](https://doc.rust-lang.org/cargo/commands/cargo-new.html), there are two options for creating a new project: `--bin` for binaries (applications) and `--lib` for libraries.

What we're designing and building here is the core part of the JSON parser that could be used by multiple consumers. Example consumers could include a command-line application (CLI), a web application server, a desktop application, and more. This means that we need to carefully consider the public API of our library that is available to these potential consumers, and this is a very important part of _libary design_.

I do think there are an abundance of tutorials and resources out there for _application design_, but comparatively fewer resources for _library design_.

</Spoiler>

## Implementation

Open the newly created project folder in your favorite IDE / text editor. All library projects in Rust start in the `src/lib.rs` file that was generated by the `cargo new --lib` command. Go ahead and open up that file, this is where we'll start.

There is already sample code in this file, including a function and a test. You can delete this code if you want, we won't need it.

### First Thing: Define the Data

It can be intimidating to get started on a blank module. My advice for this scenario and pretty much any scenario in any language where you start from scratch is: **define the data first**.

In the Introduction, we said that a JSON value is one of six distinct variants:

1. null
2. boolean
3. string
4. number
5. array
6. object

Let's choose a data type to model this! Rust uses an `enum` to represent a closed set of possible variants. From the [Rust Programming Language book](https://doc.rust-lang.org/book/ch06-01-defining-an-enum.html):

> enums give you a way of saying a value is one of a possible set of values

(Keep the link to that book open, this is called "The Book" and is the official and the best overall resource for getting started with Rust!)

Go ahead and start adding our `enum` to the `lib.rs` file. We'll start with the "basic" (non-recursive) types.

```rust
/// Representation of a JSON value
enum Value {
    /// literal characters `null`
    Null,

    /// literal characters `true` or `false`
    Boolean(bool),

    /// characters within double quotes "..."
    String(String),

    /// numbers stored as a 64-bit floating point
    Number(f64),
}
```

<NewConcept title='enum keyword'>
  As mentioned above, the `enum` keyword defines a data structure where each instance must be
  exactly one of the defined variants. "The Book" link is provided above and more information can be
  found in the [technical reference](https://doc.rust-lang.org/reference/items/enumerations.html).
</NewConcept>

<NewConcept title='Triple slash comments'>
  Rust uses triple slash (`///`) for documentation comments. When you hover on the type name or
  variant name (or any type/function/value), the corresponding comment will be shown to you.
</NewConcept>

The `enum` keyword here defined the name of the type (`Value`) and the possible variants it can have. We named these variants as `Null`, `Boolean`, `String`, and `Number`.

- `Null`: no associated data
- `Boolean`: has the associated Rust `bool`
- `String`: has the associated Rust `String`
  - It's OK they can have the same name, one is the variant name we're giving it and the other is the associated data type
- `Number`: has the associated Rust `f64` (64-bit floating point number)

Enum variants have an "OR" relationship, meaning that a `Value` is a `Null` **OR** `Boolean` **OR** `String` **OR** `Number`.

<EmphasisBox>

**Concept check**: If you've used `enum` from other languages such as C#, Java, etc. the concept of the payload/data with the variant may be new.

We can associate any data we want with the variant. This concept has been around for decades, apparently originating in the 1970s in Pascal or perhaps older, but has only recently been making its way into current "mainstream" languages. These are called "sum types" and are a necessary and fundamental part of accurately modeling data. To read more, check out [Wikipedia](https://en.wikipedia.org/wiki/Tagged_union) or an article [Sum Types are Coming](https://chadaustin.me/2015/07/sum-types/).

</EmphasisBox>

Let's add the two remaining variants now, Array and Object.

```rust
enum Value {
    // ...snip...

    /// Zero to many JSON values
    Array(Vec<Value>),

    /// String keys with JSON values
    Object(HashMap<String, Value>),
}
```

<Spoiler summary="...snip... ?">

Throughout the tutorial, I use comments with `...snip...` that indicate that this particular code is building on a previous code snippet.

</Spoiler>

These two variants are interesting because they are recursive -- Array and Object contain other `Value` inside of them. Thankfully, this is pretty easy to represent in Rust, as seen above.

- `Array`: the associated data is `Vec<Value>`, pronounced as a "vector of Value(s)"
  - A [Vec](https://doc.rust-lang.org/std/vec/struct.Vec.html) is a growable array type, analogous to a `List` in Python & C#, `vector` in C++, `Array` in JavaScript, etc.
  - It is "recursive", because the array can contain any other JSON value
- `Object`: the associated data is `HashMap<String, Value>`
  - A map between string keys and JSON values, which also makes this recursive

...and done! Users of our library will pass us some JSON string, we'll parse it and give them back this `Value`. Therefore, this `Value` data type is part of the **public API** of our library. Since it is part of our public API, let's make it public with the `pub` keyword.

```rust
pub enum Value {
    // ...snip...
}
```

<NewConcept title='pub keyword'>
  The `pub` keyword indicates that the following type/function/module/constant is publicly
  available. Read more about [Visibility and
  Privacy](https://doc.rust-lang.org/reference/visibility-and-privacy.html) for the various
  possibilities.
</NewConcept>

<Spoiler summary="A note on the Open-Closed Principle">

Data types created by the `enum` keyword are not extensible, thus perhaps violating the [Open-Closed Principle](https://en.wikipedia.org/wiki/Open%E2%80%93closed_principle), the "O" from the "SOLID principles".

> Software entities (classes, modules, functions, etc.) should be open for extension, but closed for modification.

However, our software entity here (the `Value` enum) is **purposely not** open for extension. The possible variants of JSON values are a fixed set, which allows for [exhaustive checking](https://fsharpforfunandprofit.com/posts/correctness-exhaustive-pattern-matching), and the guarantees provided by our library rely on this not being extensible. This leads to some questions about this usefulness of this principle in general give [Deconstructing SOLID design principles](https://www.tedinski.com/2019/04/02/solid-critique.html) a read which has interesting remarks on this principle.

</Spoiler>

<EmphasisBox>

#### Knowledge Check

1. What are the valid data types in JSON?
2. What is an `enum` in Rust?
3. Is there another way we could have expressed the boolean values in our `enum`?

<Spoiler summary="Answers">

1. There are exactly six valid data types in JSON: Null, String, Number, Boolean, Array, and Object.
2. An `enum` is a sum type, which models something that can be exactly one of a set of variants. Variants usually have associated data, but it is not required to.
3. Instead of a Boolean variant with `bool` data, we could have made two separate variants for True and False. What are the tradeoffs for this approach?

</Spoiler>

</EmphasisBox>

## Writing the Lexer

The next step is to write the [Lexer](https://en.wikipedia.org/wiki/Lexical_analysis). Paraphrasing from that article:

> In computer science, lexing is the process of converting a sequence of characters into a sequence of _lexical tokens_ (strings with an identified meaning)

Since this is _almost_ a self-referencing definition, let's use an example:

```json
{
  "nums": [1.2, 3.4]
}
```

This could be processed into the following _lexical tokens_:

```txt
[LeftBrace, String("nums"), Colon, LeftBracket, Float(1.2), Comma, Float(3.4), RightBracket, RightBrace]
```

Note that these tokens have a **linear** structure, we have a _sequence_ of tokens.

### Defining the Token type

Now we'll define the `Token` type, such as is seen in the previous section.
The `Token` is another _closed set_ of variants, the grammar of JSON is fixed. Open up [JSON.org](https://www.json.org/json-en.html) again, what are the possible variants of the tokens?

Let's start with the "punctuation" kind of tokens. First, create a new file named `lex.rs` next to `lib.rs`.

Next, inside of `lib.rs`, declare the new module.

```rust
// in lib.rs
mod lex;
```

<NewConcept title="mod keyword">
The `mod` keyword declares a new module.

This may be unfamiliar depending on experience in other programming languages where the module tree is determined by the file system. In Rust, the module tree is explicitly declared by the programmer. [Clear explanation of Rustâ€™s module system](https://www.sheshbabu.com/posts/rust-module-system/) explains this well.

</NewConcept>

Now that `lex.rs` has been declared a module, we can write code in it. We'll add the first few variants for `Token`.

```rust
// in lex.rs
pub enum Token {
    LeftBrace,    // "{"
    RightBrace,   // "}"
    LeftBracket,  // "["
    RightBracket, // "]"
    Comma,        // ","
    Colon,        // ":"
}
```

Next, let's define the literal tokens, which are `null`, `true`, and `false`.

```rust
pub enum Token {
    // ...snip...

    Null,    // "null"
    True,    // "true"
    False,   // "false"
}
```

Finally, we have tokens that can contain variable data, which are numbers and strings.

```rust
pub enum Token {
    // ...snip...

    Float(f64),

    /// Key of the key/value pair or string value
    String(String),
}
```

As we saw earlier with the `Value` enum, it's fine to have a variant with the same name as the type of data it contains. This is a stylistic preference, if you prefer, the variant can be named `Str`.

<EmphasisBox>

We used a single token to represent numbers, for both integers and floats.

What does the JSON specification say about supporting integers? What are the tradeoffs of doing so?

</EmphasisBox>

### Define the public API

As stated earlier, lexing is taking a sequence of characters and turning that into a sequence of tokens. In Rust terminology, that is `String -> Vec<Token>`.

Let's start that top-level `lex` function now. Use the `fn` keyword to define a function and refer to the [chapter in "The Book" on functions](https://doc.rust-lang.org/stable/book/ch03-03-how-functions-work.html).

```rust
// in lex.rs, above the Token enum
pub fn lex(input: String) -> Vec<Token> {
    Vec::new()
}
```

This is the top-level function that is public from this module (`pub` keyword).

<NewConcept title=":: (double-colon) syntax">
  The `::` is the ["path" operator](https://doc.rust-lang.org/stable/book/ch07-03-paths-for-referring-to-an-item-in-the-module-tree.html) for accessing members of a namespace/scope. In this case, it is accessing a function called `new` that is associated to `Vec`. Rust disambiguates between `::` for accessing members of a namespace/scope and `.` to access members of a value (we'll see this later).
  
  Some other languages also use `::` for a similar purpose. Ruby, for example, uses `::` as the scope operator and `.` as the message operator (sending a message to an object). Most current languages use `.` as a general "member" operator, used for both accessing members of a namespace/scope and for accessing members of a value.
</NewConcept>

### Writing Tests

Now that we have a function (well, just the start of one), we can write our first test!

Up to this point, I've been trying to introduce only one new concept at a time. However, being able to test your code is very important because it'll give you quick feedback and the ability to actually run your functions without leaving your editor. Let's rip the band-aid and show the necessary concepts for running a unit test.

```rust
// in lex.rs, below the Token enum
#[cfg(test)]
mod tests {
    use super::{lex, Token};

    #[test]
    fn comma() {
        let expected = [Token::Comma];
        let actual = lex(String::from(","));

        assert_eq!(actual, expected);
    }
}
```

This will have a compiler error on the `assert_eq!` line. Hovering over the message, there are actually two compiler errors (paraphrased and simplified below).

1. binary operation `==` cannot be applied to type `Vec<Token>`
2. `Token` doesn't implement `Debug`

The first error is because `Token` cannot be compared for equality with another `Token`, Rust doesn't generate this automatically. The second error is if the test fails, Rust will try to show you the expected result vs. actual result, but it can only do that if a Debug representation is available. To keep the scope of this tutorial smaller, I won't go into more detail but please feel free to read more on these items. To resolve these compiler errors, add the following code:

```rust
// in lex.rs, directly on the Token enum
#[derive(Debug, PartialEq)]
pub enum Token {
  // ...snip...
}
```

This provides `Token` with the ability to be compared for equality and to have a Debug representation for printing. If all is well, a "Run Test" button should appear next to the test function that you can click in VS Code. If you're not using VS Code or it's not working for some reason, you can run tests with the [cargo test](https://doc.rust-lang.org/cargo/commands/cargo-test.html) command.

Go ahead and run the test! It fails... which is expected because we haven't actually implemented anything. You should see something like this in your test output.

```
running 1 test
thread 'lex::tests::comma' panicked at 'assertion failed: `(left == right)`
  left: `[Comma]`,
 right: `[]`',
```

Now, going back to explain the new concepts from the unit test.

<NewConcept title="mod keyword">
  More of an extension of the existing module concept we are aware of, modules can be defined within a file. A file can contain multiple modules if desired.

  As stated in the previous section on modules, the programmer explicitly defines the module tree, it is not implicit based on the filesystem. In this case, the `lex` module is defining a child module named `tests`.
</NewConcept>

<NewConcept title="attributes">
  The `#[something]` syntax in the code example is an [attribute](https://doc.rust-lang.org/reference/attributes.html). This is metadata that changes how the compiler uses the following entity (module, type, function, constant, etc.).

  `#[cfg(test)]` means - "Only compile this code in the test profile". This means that the `tests` module is available for tests but will not be included in a production build.

  `#[test]` marks a function as being a unit test, the compiler will add some extra properties to it so that the test runner can find it and execute it.
</NewConcept>

<NewConcept title="use and super keywords">
  The `use` keyword brings entities (module, type, function, constant, etc.) into the current scope. It's similar to the `import` keyword in other languages.

  The `super` keyword when used in a path refers to the parent module. In this case, the current module is `lex::tests` and the parent of that is `lex`.
</NewConcept>

### Defining the Lexer struct

The [`struct` keyword](https://doc.rust-lang.org/book/ch05-00-structs.html) defines a data type for grouping together multiple related fields. This `Lexer` struct is where we'll hold the input data and keep track of the state of lexing so far. Note that it is not marked `pub`, and thus is not part of the public API of this module.

```rust
// in lex.rs
struct Lexer {
    /// Characters from the input
    chars: Vec<char>,

    /// Current index being lexed
    curr_idx: usize,
}
```

## Writing the Parser

## The nitty gritty

### Objects with duplicate keys

[RFC 8259](https://datatracker.ietf.org/doc/html/rfc8259) specifies that the names within a JSON object SHOULD be unique.

> An object whose names are all unique is interoperable in the sense that all software implementations receiving that object will agree on the name-value mappings. When the names within an object are not unique, the behavior of software that receives such an object is unpredictable.
> Many implementations report the last name/value pair only. Other implementations report an error or fail to parse the object, and some implementations report all of the name/value pairs, including duplicates.

```javascript
const str = `{"a": 1, "a": 2}`

console.log(JSON.parse(str)) // --> { a: 2 }
```

### Object Key Ordering

export default ({ children }) => <BlogsPage meta={meta}>{children}</BlogsPage>
