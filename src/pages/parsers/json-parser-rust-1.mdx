export const meta = {
  title: 'Tutorial: Writing a JSON (Rust) - Part One',
  category: 'parsers',
  type: 'tutorial',
  slug: 'json-parser-rust-1',
  tagline: 'Learn the fundamentals of parsing by building a JSON parser from scratch',
  tags: ['JSON', 'Rust'],
  publishedOn: '2023-06-10',
}

import { BlogsPage } from '../../layouts/blog'
import { EmphasisBox, Spoiler } from '../../components/blog'

<EmphasisBox>

**Intended Audience**:

- People who would like to learn about parsing
- Anyone who wants a hands-on gentle introduction to the Rust programming language

**Recommended Proficiency Level**:

- Comfortable with any statically typed language and familiar with a terminal / command line
- No Rust experience is needed!

**Learning Method**:

This is a hands-on tutorial, just reading through won't get you much. You'll get the most out of it by actually firing up a code editor and following along!

</EmphasisBox>

## Introduction

In this tutorial, we will learn how to write a JSON parser from scratch, using the [Rust programming language](https://www.rust-lang.org/).

We will create a [library](<https://en.wikipedia.org/wiki/Library_(computing)>), so that users of our library can pass in the JSON string and they'll receive back parsed JSON.

This is a two part series:

1. Recursive Descent (top-down) - This article!
2. Parser Combinators (bottom-up) - Not written yet

The code for this article uses a **procedural/imperative** style, and should be familiar for anyone coming from languages using those styles. We won't get into advanced Rust features, and every new concept will be explained in detail.

To understand "JSON parser", we'll first ensure we understand "JSON" and "parser" in the next sections.

### What is JSON?

JavaScript Object Notation ([JSON](https://www.json.org)) is a format for exchanging and storing data. As the name implies, the syntax is based on JavaScript, but it is a language-independent data format.

The possible data types in JSON are fixed (a _closed set_), meaning that the format itself is not extensible. There are exactly six possible data types that can be transmitted via JSON, also described in the previous link.

1. `null`
2. boolean: `true` or `false`
3. string: `"a string"`
4. number: `2`, `-2`, `2.5`, `2E+32`, `2e-16`
5. array: `[ json_value, json_value, ... ]`
6. object: `{ "key": json_value, ... }`

The "array" and "object" types are **recursive** - they contain other JSON values.

<Spoiler summary="Edge case: JSON syntax as a subset of Javascript syntax">

Until JavaScript's 2019 edition (ES2019), JSON syntax was _almost_ a subset of JavaScript syntax. There was one edge case -- JSON strings could contain the Unicode characters U+2028 (LINE SEPARATOR) and U+2029 (PARAGRAPH SEPARATOR) unescaped while in JavaScript they had to be escaped.

This means that valid JSON might not be valid JavaScript, which breaks that subset relationship. As of ES2019, with the approval and implementation of the [json-superset proposal](https://github.com/tc39/proposal-json-superset) proposal, JSON syntax is now a proper subset of JavaScript syntax.

</Spoiler>

<Spoiler summary="Edge case: Are JSON semantics a subset of JavaScript semantics?">

Although JSON is a **syntactic** subset of JavaScript, it is not necessarily a **semantic** subset of Javascript. For example, the following produces a different result when parsed as Javascript vs. JSON.

```javascript
const str = `[{ "__proto__": [] }]`

const fromJS = eval(str)
const fromJSON = JSON.parse(str)
```

The `fromJS` result is an array with one item, where that item is an Object that has Array as its prototype.
The `fromJSON` result is also an array with one item, and that item is an Object who has an own property with
an identifier of `__proto__` (you can run this code in your browser console and compare the result of `Object.getOwnPropertyNames(x)` for `fromJS` and `fromJSON`).

Edge cases are weird, right?

</Spoiler>

### What is Parsing?

In programming, "parsing" is transforming less-structured input into more-structured output by applying knowledge of the expected shape(s) of the data. A "parser" is a function that does this. By definition, this transformation might fail if the input isn't compatible with the desired output.

This is a fairly flexible interpretation, and perhaps a little vague, so some breakdown on the statement above:

- _less-structured input_ examples:
  - A `String` is a common input format for text-based data, which is a sequence of characters (what is a "character"? An entire article could be written on this)
  - A stream of bytes is also unstructured input, for example audio data that is parsed by some audio player program
- _more-structured output_ examples:
  - JSON structure - rather than a flat sequence of characters, it now has an organized representation with the six data variants discussed in the Introduction.
  - HTTP request - An incoming HTTP request is a stream of bytes, but it can be parsed into a more-structured representation that has the method, path, protocol, headers, body, etc.
- _knowledge of the expected shape_:
  - We can't parse a less-structured input without knowing what it possibly could be.
  - We apply that knowledge when parsing, to check if the input adheres to the expected shape
- _might fail_:
  - If the input doesn't align to the expectations, then the parsing fails
  - Example: If the incoming String is not in JSON format, then it is not JSON and the parsing fails
  - Example: If the incoming POST data to the `/api/invoice` endpoint does not have the fields necessary for an `Invoice`, then it is not an `Invoice` and parsing fails
  - Parsing failures are **not exceptional**. Any time we deal with data from the outside world, the possibility of parsing failure is as equally plausible as parsing success.

## Project Setup

Enough talk, let's get started!

### Development Environment Setup

The Rust compiler is available on all popular operating systems. If you don't already have it installed, head over to [rust-lang.org](https://www.rust-lang.org/) and follow the instructions to get started. This setup page also has links to activating Rust support in various code editors/IDE.

Personally, I use Visual Studio Code (VS Code) running in Windows Subsystem for Linux (WSL), but this tutorial can be followed on any operating system and code editor that Rust supports.

### Project Setup

We're going to create a _library_ for our JSON parser. In your command line, navigate to the directory where you want this project to exist. For example: `~/tutorials/rust`. Run the following command to generate a new Rust library project:

```
cargo new --lib json_parser
```

This creates a new folder, `json_parser`, that contains the new Rust project.

<Spoiler summary="Why create a library?">

From the [documentation for `cargo new`](https://doc.rust-lang.org/cargo/commands/cargo-new.html), there are two options for creating a new project: `--bin` for binaries (applications) and `--lib` for libraries.

What we're designing and building here is the core part of the JSON parser that could be used by multiple consumers. Example consumers could include a command-line application (CLI), a web application server, a desktop application, and more. This means that we need to carefully consider the public API of our library that is available to these potential consumers, and this is a very important part of _libary design_.

I do think there are an abundance of tutorials and resources out there for _application design_, but comparatively fewer resources for _library design_.

</Spoiler>

## Implementation

Open the newly created project folder in your favorite IDE / text editor. All library projects in Rust start in the `src/lib.rs` file that was generated by the `cargo new --lib` command. Go ahead and open up that file, this is where we'll start.

There is already sample code in this file, including a function and a test. You can delete this code if you want, we won't need it.

### First Thing: Define the Data

It can be intimidating to get started on a blank module. My advice for this scenario and pretty much any scenario in any language where you start from scratch is: **define the data first**.

In the Introduction, we said that a JSON value is one of six distinct variants:

1. null
2. boolean
3. string
4. number
5. array
6. object

Let's choose a data type to model this! Rust uses an `enum` to represent a closed set of possible variants. From the [Rust Programming Language book](https://doc.rust-lang.org/book/ch06-01-defining-an-enum.html):

> enums give you a way of saying a value is one of a possible set of values

(Keep the link to that book open, this is the official and the best overall resource for getting started with Rust!)

Go ahead and start adding our `enum` to the `lib.rs` file. We'll start with the "basic" (non-recursive) types.

```rust
/// Representation of a JSON value
enum Value {
    /// literal characters `null`
    Null,

    /// literal characters `true` or `false`
    Boolean(bool),

    /// characters within double quotes "..."
    String(String),

    /// numbers stored as a 64-bit floating point
    Number(f64),
}
```

<Spoiler summary='Triple slash?'>
  Rust uses triple slash (`///`) for documentation comments. When you hover on the type name or
  variant name, the corresponding comment will be shown to you.
</Spoiler>

The `enum` keyword here defined the name of the type (`Value`) and the possible variants it can have. We named these variants as `Null`, `Boolean`, `String`, and `Number`.

- `Null`: no associated data
- `Boolean`: has the associated Rust `bool`
- `String`: has the associated Rust `String`
  - It's OK they can have the same name, one is the variant name we're giving it and the other is the associated data type
- `Number`: has the associated Rust `f64` (64-bit floating point number)

Enum variants have an "OR" relationship, meaning that a `Value` is a `Null` **OR** `Boolean` **OR** `String` **OR** `Number`.

<EmphasisBox>

**Concept check**: If you've used `enum` from other languages such as C#, Java, etc. the concept of the payload/data with the variant may be new.

We can have a powerful and flexible approach here by associating any data we want with the variant. These have been around for decades, apparently originating in the 1970s in Pascal or perhaps older. These are called "sum types" or "tagged unions", to read more, check out [Wikipedia](https://en.wikipedia.org/wiki/Tagged_union) or a blog article [Sum Types are Coming](https://chadaustin.me/2015/07/sum-types/).

</EmphasisBox>

Let's add the two remaining variants now, Array and Object.

```rust
pub enum Value {
    // ...snip...

    /// Zero to many JSON values
    Array(Vec<Value>),

    /// String keys with JSON values
    Object(HashMap<String, Value>),
}
```

<Spoiler summary="...snip... ?">

Throughout the tutorial, I use comments with `...snip...` that indicate that this particular code is building on a previous code snippet.

</Spoiler>

These two variants are interesting because they are recursive -- Array and Object contain other `Value` inside of them. Thankfully, this is pretty easy to represent in Rust, as seen above.

- `Array`: the associated data is `Vec<Value>`, pronounced as a "vector of Value(s)"
  - A [Vec](https://doc.rust-lang.org/std/vec/struct.Vec.html) is a growable array type, analogous to a `List` in Python & C#, `vector` in C++, `Array` in JavaScript, etc.
  - It is "recursive", because the array can contain any other JSON value
- `Object`: the associated data is `HashMap<String, Value>`
  - A map between string keys and JSON values, which also makes this recursive

...and done! Users of our library will pass us some JSON string, we'll parse it and give them back this `Value`. Therefore, this `Value` data type is part of the **public API** of our library.

<Spoiler summary="A note on the Open-Closed Principle">

Data types created by the `enum` keyword are not extensible, thus perhaps violating the [Open-Closed Principle](https://en.wikipedia.org/wiki/Open%E2%80%93closed_principle), the "O" from the "SOLID principles".

> Software entities (classes, modules, functions, etc.) should be open for extension, but closed for modification.

However, our software entity here (the `Value` enum) is **purposely not** open for extension. The possible variants of JSON values are a fixed set, which allows for [exhaustive checking](https://fsharpforfunandprofit.com/posts/correctness-exhaustive-pattern-matching), and the guarantees provided by our library rely on this not being extensible. This leads to some questions about this usefulness of this principle in general give [Deconstructing SOLID design principles](https://www.tedinski.com/2019/04/02/solid-critique.html) a read which has interesting remarks on this principle.

</Spoiler>

<EmphasisBox>

#### Knowledge Check

1. What are the valid data types in JSON?
2. What is an `enum` in Rust?
3. Is there another way we could have expressed the boolean values in our `enum`?

<Spoiler summary="Answers">

1. There are exactly six valid data types in JSON: Null, String, Number, Boolean, Array, and Object.
2. An `enum` is a sum type, which models something that can be exactly one of a set of variants. Variants may also have associated data.
3. Instead of a Boolean variant with `bool` data, we could have made two separate variants for True and False.

</Spoiler>

</EmphasisBox>

## Writing the Lexer

The next step is to write the [Lexer](https://en.wikipedia.org/wiki/Lexical_analysis). Paraphrasing from that article:

> In computer science, lexing is the process of converting a sequence of characters into a sequence of _lexical tokens_ (strings with an identified meaning)

Since this is _almost_ a self-referencing definition, let's use an example:

```json
{
  "nums": [1.2, 3.4]
}
```

This could be processed into the following _lexical tokens_:

```txt
[LeftBrace, String("nums"), Colon, LeftBracket, Float(1.2), Comma, Float(3.4), RightBracket, RightBrace]
```

Note that these tokens have a **linear** structure, we have a _sequence_ of tokens.

### Defining the Token type

Now we'll define the `Token` type, such as is seen in the previous section.
The `Token` is another _closed set_ of variants, the grammar of JSON is fixed. Open up [JSON.org](https://www.json.org/json-en.html) again, what are the possible variants of the tokens?

Let's start with the "punctuation" kind of tokens. First, create a new file named `lex.rs` next to `lib.rs`.

Next, inside of `lib.rs`, declare the new module.

```rust
// in lib.rs
mod lex;
```

Now that `lex.rs` has been declared a module, we can write code in it. This may be unfamiliar depending on experience in other programming languages where the module tree is determined by the file system. In Rust, the module tree is explicitly defined by the programmer. [Clear explanation of Rust’s module system](https://www.sheshbabu.com/posts/rust-module-system/) explains this well.

Now, we'll add the first few variants for `Token`.

```rust
// in lex.rs
pub enum Token {
    LeftBrace,    // "{"
    RightBrace,   // "}"
    LeftBracket,  // "["
    RightBracket, // "]"
    Comma,        // ","
    Colon,        // ":"
}
```

Next, let's define the literal tokens, which are `null`, `true`, and `false`.

```rust
pub enum Token {
    // ...snip...

    Null,    // "null"
    True,    // "true"
    False,   // "false"
}
```

Finally, we have tokens that can contain variable data, which are numbers and strings.

```rust
pub enum Token {
    // ...snip...

    Float(f64),

    /// Key of the key/value pair or string value
    String(String),
}
```

As we saw earlier with the `Value` enum, it's fine to have a variant with the same name as the type of data it contains. This is a stylistic preference, if you prefer, the variant can be named `Str`.

<EmphasisBox>

We used a single token to represent numbers because JSON doesn't distinguish between integers and floats. Is there any benefit to separating integers and floats in our parser? What are the tradeoffs?

</EmphasisBox>

### Defining the Lexer struct

The [`struct` keyword](https://doc.rust-lang.org/book/ch05-00-structs.html) defines a data type for grouping together multiple related fields.

```rust
// in lex.rs
struct Lexer {
    /// Characters from the input
    chars: Vec<char>,

    /// Current index being lexed
    curr_idx: usize,
}
```

This `Lexer` struct is where we'll hold the input data and keep track of the state of lexing so far.

The next thing I like to do after defining the data is defining the top-level functions. As stated earlier, lexing is taking a sequence of character and turning that into a sequence of tokens. In Rust terminology, that is this transformation:

```
String -> Vec<Token>
```

Let's start that function now.

```rust
// Below the Lexer struct
pub fn lex(input: String) -> Vec<Token> {
    todo!()
}
```

<EmphasisBox>
  The `todo!()` is a built-in macro that allows the code to compile even when it's not implemented
  yet. If this function were to be actually executed, it would fail at runtime. That's OK, this is a
  very useful tool to map out the functions that you want to implement later.
</EmphasisBox>

## Writing the Parser

## The nitty gritty

### Objects with duplicate keys

[RFC 8259](https://datatracker.ietf.org/doc/html/rfc8259) specifies that the names within a JSON object SHOULD be unique.

> An object whose names are all unique is interoperable in the sense that all software implementations receiving that object will agree on the name-value mappings. When the names within an object are not unique, the behavior of software that receives such an object is unpredictable.
> Many implementations report the last name/value pair only. Other implementations report an error or fail to parse the object, and some implementations report all of the name/value pairs, including duplicates.

```javascript
const str = `{"a": 1, "a": 2}`

console.log(JSON.parse(str)) // --> { a: 2 }
```

### Object Key Ordering

export default ({ children }) => <BlogsPage meta={meta}>{children}</BlogsPage>
