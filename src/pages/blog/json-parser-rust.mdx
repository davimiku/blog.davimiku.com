---
title: Writing a JSON parser in Rust
tagline: Learn the fundamentals of lexing and parsing to build a JSON parser from scratch
tags:
  - Lexers
  - Parsers
  - Rust
---

import { Spoiler } from '../../components/blog/spoiler'

## Understanding the JSON syntax and types

Types include

- object (`{ "key": json_value }`)
- array (`[ json_value, json_value ]`)
- number (`2`, `-2`, `2.5`, `2E+32`, `2e-16`)
- string (`"a string"`)
- boolean (`true` or `false`)
- null

<Spoiler summary="JSON syntax is a subset of Javascript syntax">

As of ES2019, JSON syntax is a subset of Javascript syntax when [unicode characters
U+2028 and U+2029](https://github.com/tc39/proposal-json-superset) are allowed to exist in JS strings unescaped.

JSON is not necessarily a **semantic** subset of Javascript. For example, the following produces a different result when
parsed as Javascript vs. JSON.

```javascript
const str = `[{ "__proto__": [] }]`

const fromJS = eval(str)
const fromJSON = JSON.parse(str)
```

The `fromJS` result is an array with one item, where that item is an Object that has Array as its prototype.
The `fromJSON` result is also an array with one item, and that item is an Object who has an own property with
an identifier of `__proto__` (compare the result of `Object.getOwnPropertyNames(x)` for each `fromJS` and `fromJSON`).

</Spoiler>

### Defining the types for JSON values

Start with the easy values, the primitives:

```rust
pub enum Value {
  /// literal characters `null`
  Null,

  /// literal characters `true` or `false`
  Bool(bool),

  /// characters within double quotes "..."
  String(String),
}
```

Add on the non-primitives:

```rust
pub enum Value {
  /// literal characters `null`
  Null,

  /// literal characters `true` or `false`
  Bool(bool),

  /// characters within double quotes "..."
  String(String),

  /// Zero to many JSON values in an array
  Array(Vec<Value>),

  /// Key/value pairs
  Object(BTreeMap<String, Value>),
}
```

Quiz: Which value is missing?

Number is not quite straightforward in Rust, the available types are more granular. While the [Number in Javascript](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Number) (and JSON!)
represents a `double` value, or in other words a 64-bit floating value as described in [IEEE 754](https://en.wikipedia.org/wiki/IEEE_754).

For our purposes, we will explore how to capture JSON numbers in two ways, as an integer `i64` and as a floating value `f64`.

```rust
pub enum Number {
  /// Number without a fractional component
  Int(i64),

  /// Number that has a fractional component
  Float(f64),
}
```

Finally, add this enum to our overall `Value` enum.

```rust
pub enum Value {
  // ...

  /// Number value
  Number(Number),
}
```

## Writing the Lexer

### Creating the Token type

```rust
#[derive(Debug, PartialEq, Clone)]
pub enum TokenKind {
    /// Literals
    Int(i64),
    Float(f64),
    Null,
    Bool(bool),

    /// Key of the key/value pair or string value
    String(String),

    /// Punctuation
    LeftBrace,
    RightBrace,
    LeftBracket,
    RightBracket,
    Comma,
    Colon,

    EOF,
}
```

OPTIONAL: Implement `Display` for the Token.
This will allow having a custom format for printing the token out, which can be useful for debugging.

```rust
fn example_print(token: Token) {
  // Requires `Display` to be implemented for Token
  println!("{}", token);

  // Requires `Debug` to be implemented for Token, which can be derived automatically
  println!("{:?}", token);
}
```

```rust
// Note "Result as FmtResult", I typically avoid shadowing the regular `Result`
// enum for clarity, although it can be convenient at times.
use std::fmt::{Display, Formatter, Result as FmtResult, Write};

// ...

//
impl Display for TokenKind {
    fn fmt(&self, f: &mut Formatter) -> FmtResult {
        match self {
            TokenKind::LeftBracket => f.write_char('['),
            TokenKind::RightBracket => f.write_char(']'),
            TokenKind::LeftBrace => f.write_char('{'),
            TokenKind::RightBrace => f.write_char('}'),
            TokenKind::Comma => f.write_char(','),
            TokenKind::Colon => f.write_char(':'),
            TokenKind::String(val) => write!(f, "{:?}", val),
            TokenKind::Int(val) => write!(f, "{:?}", val),
            TokenKind::Float(val) => write!(f, "{:?}", val),
            TokenKind::Bool(val) => write!(f, "{:?}", val),
            TokenKind::Null => f.write_str("null"),
            TokenKind::EOF => f.write_str("EOF"),
        }
    }
}

//
impl Display for Token {
    fn fmt(&self, f: &mut Formatter) -> FmtResult {
        f.write_fmt(format_args!(
            "token '{}' at row {}, col {}",
            self.kind, self.location.row, self.location.col,
        ))
    }
}

```

### Rust Traits: The `Iterator`

We'll first start be defining the `struct` for the Lexer, which will take the character input and output our `Token`s.

```rust
pub struct Lexer<I: Iterator<Item = char>> {
  /// Iterator for chars from the input
  char_iter: I,
}
```

At first, this syntax can be confusing without much experience with Rust or other languages with generics. In this case, `I` represents
a generic type parameter which can be anything is an `Iterator` for `char`acters.

A more explicit (and semantically equivalent) way of writing this is below.

```rust
pub struct Lexer<I>
where
    I: Iterator<Item = char>,
{
  /// Iterator for chars from the input
  char_iter: I,
}
```

We'll want a few other fields in the lexer.

```rust
/// The Lexer produces tokens from the character input
pub struct Lexer<I: Iterator<Item = char>> {
    /// Iterator for chars from the input
    char_iter: I,

    /// Current Location (row/col) of the lexer in the input
    location: Location,

    /// The current character in the iterator
    curr: Option<char>,

    /// The next character in the iterator
    next: Option<char>,
}
```

## Writing the Parser

## The nitty gritty

### Objects with duplicate keys

The RFC specifies that the names within an object SHOULD be unique,
https://datatracker.ietf.org/doc/html/rfc8259

> An object whose names are all unique is interoperable in the sense
> that all software implementations receiving that object will agree on
> the name-value mappings. When the names within an object are not
> unique, the behavior of software that receives such an object is
> unpredictable. Many implementations report the last name/value pair
> only. Other implementations report an error or fail to parse the
> object, and some implementations report all of the name/value pairs,
> including duplicates.

```javascript
const str = `{"a": 1, "a": 2}`

console.log(JSON.parse(str)) // --> { a: 2 }
```

### Object Key Ordering
